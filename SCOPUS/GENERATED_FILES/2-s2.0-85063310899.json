{"Title": "Nonrigid optical flow ground truth for real-world scenes with time-varying shading effects", "Year": 2017, "Source": "IEEE Robot. Autom.", "Volume": "2", "Issue": 1, "Art.No": null, "PageStart": 231, "PageEnd": 238, "CitedBy": 11, "DOI": "10.1109/LRA.2016.2592513", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85063310899&origin=inward", "Abstract": "\u00a9 2016 IEEE.In this letter, we present a dense ground truth dataset of nonrigidly deforming real-world scenes. Our dataset contains both long and short video sequences, and enables the quantitatively evaluation for RGB-based tracking and registration methods. To construct ground truth for the RGB sequences, we simultaneously capture Near-Infrared (NIR) image sequences where dense markers - visible only in NIR - represent ground-truth positions. This allows for comparison with automatically tracked RGB positions and the formation of error metrics. Most previous datasets containing nonrigidly deforming sequences are based on synthetic data. Our capture protocol enables us to acquire real-world deforming objects with realistic photometric effects - such as blur and illumination change - as well as occlusion and complex deformations. A public evaluation website is constructed to allow for ranking of RGB-image-based optical flow and other dense tracking algorithms, with various statistical measures. Furthermore, we present an RGB-NIR multispectral optical flow model allowing for energy optimization by adoptively combining featured information from both the RGB and the complementary NIR channels. In our experiments we evaluate eight existing RGB-based optical flow methods on our new dataset. We also evaluate our hybrid optical flow algorithm by comparing to two existing multispectral approaches, as well as varying our input channels across RGB, NIR, and RGB-NIR.", "AuthorKeywords": ["Dense ground truth", "GRB-NIR imaging", "multispectral optical flow", "near-infrared (NIR) dyes", "optical flow"], "IndexKeywords": ["Ground truth", "Ground-truth dataset", "Multi-spectral", "Near-infrared dyes", "NIR Imaging", "Optical flow algorithm", "Optical flow methods", "Registration methods"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85063310899", "SubjectAreas": [["Control and Systems Engineering", "ENGI", "2207"], ["Biomedical Engineering", "ENGI", "2204"], ["Human-Computer Interaction", "COMP", "1709"], ["Mechanical Engineering", "ENGI", "2210"], ["Computer Vision and Pattern Recognition", "COMP", "1707"], ["Computer Science Applications", "COMP", "1706"], ["Control and Optimization", "MATH", "2606"], ["Artificial Intelligence", "COMP", "1702"]], "AuthorData": {"57192673420": {"Name": "Li W.", "AuthorID": "57192673420", "AffiliationID": "60022148", "AffiliationName": "Department of Computer Science, University College London"}, "55925162500": {"Name": "Lv Z.", "AuthorID": "55925162500", "AffiliationID": "60022148", "AffiliationName": "Department of Computer Science, University College London"}, "6506582396": {"Name": "Cosker D.", "AuthorID": "6506582396", "AffiliationID": "60030480", "AffiliationName": "Centre for the Analysis of Motion, Entertainment Research and Applications (CAMERA), University of Bath"}, "55722062700": {"Name": "Brown M.", "AuthorID": "55722062700", "AffiliationID": "60006191", "AffiliationName": "Google, Mountain View"}}}