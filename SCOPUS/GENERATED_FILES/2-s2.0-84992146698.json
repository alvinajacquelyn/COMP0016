{"Title": "Big data need big theory too", "Year": 2016, "Source": "Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.", "Volume": "374", "Issue": 2080, "Art.No": null, "PageStart": null, "PageEnd": null, "CitedBy": 79, "DOI": "10.1098/rsta.2016.0153", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84992146698&origin=inward", "Abstract": "\u00a9 2016 The Author(s) Published by the Royal Society. All rights reserved.The current interest in big data, machine learning and data analytics has generated the widespread impression that such methods are capable of solving most problems without the need for conventional scientific methods of inquiry. Interest in these methods is intensifying, accelerated by the ease with which digitized data can be acquired in virtually all fields of endeavour, from science, healthcare and cybersecurity to economics, social sciences and the humanities. In multiscale modelling, machine learning appears to provide a shortcut to reveal correlations of arbitrary complexity between processes at the atomic, molecular, meso-and macroscales. Here, we point out the weaknesses of pure big data approaches with particular focus on biology and medicine, which fail to provide conceptual accounts for the processes to which they are applied. No matter their 'depth' and the sophistication of data-driven methods, such as artificial neural nets, in the end they merely fit curves to existing data. Not only do these methods invariably require far larger quantities of data than anticipated by big data aficionados in order to produce statistically reliable results, but they can also fail in circumstances beyond the range of the data used to train them because they are not designed to model the structural characteristics of the underlying system. We argue that it is vital to use theory as a guide to experimental design for maximal efficiency of data collection and to produce reliable predictive models and conceptual knowledge. Rather than continuing to fund, pursue and promote 'blind' big data projects with massive budgets, we call for more funding to be allocated to the elucidation of the multiscale and stochastic processes controlling the behaviour of complex systems, including those of life, medicine and healthcare. This article is part of the themed issue 'Multiscale modelling at the physics-chemistry-biology interface'.", "AuthorKeywords": ["Big data", "Biomedicine", "Epistemology", "Machine learning", "Personalized medicine"], "IndexKeywords": ["Artificial neural net", "Biology and medicine", "Biomedicine", "Conceptual knowledge", "Epistemology", "Multi-scale modelling", "Personalized medicines", "Structural characteristics", "Computer Simulation", "Database Management Systems", "Datasets as Topic", "Information Storage and Retrieval", "Models, Theoretical", "User-Computer Interface"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 1, "EID": "2-s2.0-84992146698", "SubjectAreas": [["Mathematics (all)", "MATH", "2600"], ["Engineering (all)", "ENGI", "2200"], ["Physics and Astronomy (all)", "PHYS", "3100"]], "AuthorData": {"7005747590": {"Name": "Coveney P.", "AuthorID": "7005747590", "AffiliationID": "60022148", "AffiliationName": "Centre for Computational Science, University College London"}, "57203104116": {"Name": "Dougherty E.", "AuthorID": "57203104116", "AffiliationID": "60020547", "AffiliationName": "Center for Bioinformatics and Genomic Systems Engineering, Texas A and M University"}, "57191611845": {"Name": "Highfeld R.", "AuthorID": "57191611845", "AffiliationID": "60009319", "AffiliationName": "Science Museum"}}}