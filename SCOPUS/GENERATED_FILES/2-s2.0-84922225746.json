{"Title": "Orientation Selectivity in Inhibition-Dominated Networks of Spiking Neurons: Effect of Single Neuron Properties and Network Dynamics", "Year": 2015, "Source": "PLoS Comput. Biol.", "Volume": "11", "Issue": 1, "Art.No": null, "PageStart": null, "PageEnd": null, "CitedBy": 10, "DOI": "10.1371/journal.pcbi.1004045", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84922225746&origin=inward", "Abstract": "\u00a9 2015 Sadeh, Rotter.The neuronal mechanisms underlying the emergence of orientation selectivity in the primary visual cortex of mammals are still elusive. In rodents, visual neurons show highly selective responses to oriented stimuli, but neighboring neurons do not necessarily have similar preferences. Instead of a smooth map, one observes a salt-and-pepper organization of orientation selectivity. Modeling studies have recently confirmed that balanced random networks are indeed capable of amplifying weakly tuned inputs and generating highly selective output responses, even in absence of feature-selective recurrent connectivity. Here we seek to elucidate the neuronal mechanisms underlying this phenomenon by resorting to networks of integrate-and-fire neurons, which are amenable to analytic treatment. Specifically, in networks of perfect integrate-and-fire neurons, we observe that highly selective and contrast invariant output responses emerge, very similar to networks of leaky integrate-and-fire neurons. We then demonstrate that a theory based on mean firing rates and the detailed network topology predicts the output responses, and explains the mechanisms underlying the suppression of the common-mode, amplification of modulation, and contrast invariance. Increasing inhibition dominance in our networks makes the rectifying nonlinearity more prominent, which in turn adds some distortions to the otherwise essentially linear prediction. An extension of the linear theory can account for all the distortions, enabling us to compute the exact shape of every individual tuning curve in our networks. We show that this simple form of nonlinearity adds two important properties to orientation selectivity in the network, namely sharpening of tuning curves and extra suppression of the modulation. The theory can be further extended to account for the nonlinearity of the leaky model by replacing the rectifier by the appropriate smooth input-output transfer function. These results are robust and do not depend on the state of network dynamics, and hold equally well for mean-driven and fluctuation-driven regimes of activity.", "AuthorKeywords": null, "IndexKeywords": ["Action Potentials", "Animals", "Mice", "Models, Neurological", "Nerve Net", "Neurons"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 1, "EID": "2-s2.0-84922225746", "SubjectAreas": [["Ecology, Evolution, Behavior and Systematics", "AGRI", "1105"], ["Modeling and Simulation", "MATH", "2611"], ["Ecology", "ENVI", "2303"], ["Molecular Biology", "BIOC", "1312"], ["Genetics", "BIOC", "1311"], ["Cellular and Molecular Neuroscience", "NEUR", "2804"], ["Computational Theory and Mathematics", "COMP", "1703"]], "AuthorData": {"55928013100": {"Name": "Sadeh S.", "AuthorID": "55928013100", "AffiliationID": "60008988", "AffiliationName": "Bernstein Center Freiberg, University of Freiberg"}, "7004581948": {"Name": "Rotter S.", "AuthorID": "7004581948", "AffiliationID": "60008988", "AffiliationName": "Bernstein Center Freiberg, University of Freiberg"}}}