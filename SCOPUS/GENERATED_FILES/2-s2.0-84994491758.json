{"Title": "Do wholes become more than the sum of their parts in the rodent (Rattus Norvegicus) visual system? A test case with the configural superiority effect", "Year": 2016, "Source": "Eur. J. Neurosci.", "Volume": "44", "Issue": 8, "Art.No": null, "PageStart": 2593, "PageEnd": 2599, "CitedBy": 2, "DOI": "10.1111/ejn.13350", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84994491758&origin=inward", "Abstract": "\u00a9 2016 Federation of European Neuroscience Societies and John Wiley & Sons LtdThe rodent has been used to model various aspects of the human visual system, but it is unclear to what extent human visual perception can be modelled in the rodent. Research suggests rodents can perform invariant object recognition tasks in a manner comparable to humans. There is further evidence that rodents also make use of certain grouping cues, but when performing a shape discrimination they have a tendency to rely much more on local image cues than human participants. In the current work, we exploit the fact that humans sometimes discriminate better between whole shapes, rather than the parts from which they are constructed, to ask whether rodents show a classic Configural Superiority Effect. Using touchscreen-equipped operant boxes, rats were trained to discriminate \u2018part\u2019 or \u2018whole\u2019 images based off of those used by J. R. Pomerantz et al. () J Exp Psychol Hum Percept Perform, 3, 422\u2013435. Here, we show that rats show no advantage for wholes and that they perform better when presented with simpler image parts, a pattern of effect opposite to what was seen in humans when highly comparable stimuli were used. These results add to our understanding of the similarities and differences between the human and rodent visual system, and suggest that the rodent visual system may not compute part whole relationships in a way comparable to humans. These results are significant from both a comparative anatomy perspective, and of particular relevance for those wishing to use rodents to model visuo-perceptual deficits associated with human psychiatric disorders.", "AuthorKeywords": ["Gestalt", "touch screen", "translation", "visual perception"], "IndexKeywords": ["Animals", "Cues", "Form Perception", "Nerve Net", "Pattern Recognition, Visual", "Rats", "Reaction Time", "Visual Perception"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-84994491758", "SubjectAreas": [["Neuroscience (all)", "NEUR", "2800"]], "AuthorData": {"12792633800": {"Name": "Talpos J.", "AuthorID": "12792633800", "AffiliationID": "60029830", "AffiliationName": "National Center for Toxicological Research"}, "56661927000": {"Name": "Olley J.", "AuthorID": "56661927000", "AffiliationID": "60072269", "AffiliationName": "Department of Neuroscience, Janssen Research and Development"}, "57191886271": {"Name": "Riordan J.", "AuthorID": "57191886271", "AffiliationID": "60072269", "AffiliationName": "Department of Neuroscience, Janssen Research and Development"}, "55353081200": {"Name": "Steckler T.", "AuthorID": "55353081200", "AffiliationID": "60072269", "AffiliationName": "Department of Neuroscience, Janssen Research and Development"}, "22984662400": {"Name": "de-Wit L.", "AuthorID": "22984662400", "AffiliationID": "60022148", "AffiliationName": "Cognition and Language Sciences, University College London"}}}