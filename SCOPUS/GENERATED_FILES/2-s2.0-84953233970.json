{"Title": "Simple Plans or Sophisticated Habits? State, Transition and Learning Interactions in the Two-Step Task", "Year": 2015, "Source": "PLoS Comput. Biol.", "Volume": "11", "Issue": 12, "Art.No": null, "PageStart": null, "PageEnd": null, "CitedBy": 37, "DOI": "10.1371/journal.pcbi.1004648", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84953233970&origin=inward", "Abstract": "\u00a9 2015 Akam et al.The recently developed \u2018two-step\u2019 behavioural task promises to differentiate model-based from model-free reinforcement learning, while generating neurophysiologically-friendly decision datasets with parametric variation of decision variables. These desirable features have prompted its widespread adoption. Here, we analyse the interactions between a range of different strategies and the structure of transitions and outcomes in order to examine constraints on what can be learned from behavioural performance. The task involves a trade-off between the need for stochasticity, to allow strategies to be discriminated, and a need for determinism, so that it is worth subjects\u2019 investment of effort to exploit the contingencies optimally. We show through simulation that under certain conditions model-free strategies can masquerade as being model-based. We first show that seemingly innocuous modifications to the task structure can induce correlations between action values at the start of the trial and the subsequent trial events in such a way that analysis based on comparing successive trials can lead to erroneous conclusions. We confirm the power of a suggested correction to the analysis that can alleviate this problem. We then consider model-free reinforcement learning strategies that exploit correlations between where rewards are obtained and which actions have high expected value. These generate behaviour that appears model-based under these, and also more sophisticated, analyses. Exploiting the full potential of the two-step task as a tool for behavioural neuroscience requires an understanding of these issues.", "AuthorKeywords": null, "IndexKeywords": ["Choice Behavior", "Computer Simulation", "Habits", "Humans", "Models, Neurological", "Models, Statistical", "Reinforcement (Psychology)", "Reversal Learning", "Task Performance and Analysis"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 1, "EID": "2-s2.0-84953233970", "SubjectAreas": [["Ecology, Evolution, Behavior and Systematics", "AGRI", "1105"], ["Modeling and Simulation", "MATH", "2611"], ["Ecology", "ENVI", "2303"], ["Molecular Biology", "BIOC", "1312"], ["Genetics", "BIOC", "1311"], ["Cellular and Molecular Neuroscience", "NEUR", "2804"], ["Computational Theory and Mathematics", "COMP", "1703"]], "AuthorData": {"36776755500": {"Name": "Akam T.", "AuthorID": "36776755500", "AffiliationID": "60002634", "AffiliationName": "Department of Experimental Psychology, University of Oxford"}, "7203063633": {"Name": "Costa R.", "AuthorID": "7203063633", "AffiliationID": "60113882", "AffiliationName": "Champalimaud Centre for the Unknown"}, "7006914663": {"Name": "Dayan P.", "AuthorID": "7006914663", "AffiliationID": "60084280, 60022148", "AffiliationName": "Gatsby Computational Neuroscience Unit, UCL"}}}