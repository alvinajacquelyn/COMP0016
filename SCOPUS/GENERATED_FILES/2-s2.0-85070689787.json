{"Title": "Learning reward frequency over reward probability: A tale of two learning rules", "Year": 2019, "Source": "Cognition", "Volume": "193", "Issue": null, "Art.No": null, "PageStart": null, "PageEnd": null, "CitedBy": 1, "DOI": "10.1016/j.cognition.2019.104042", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070689787&origin=inward", "Abstract": "\u00a9 2019 Elsevier B.V.Learning about the expected value of choice alternatives associated with reward is critical for adaptive behavior. Although human choice preferences are affected by the presentation frequency of reward-related alternatives, this may not be captured by some dominant models of value learning, such as the delta rule. In this study, we examined whether reward learning is driven more by learning the probability of reward provided by each option, or how frequently each option has been rewarded, and assess how well models based on average reward (e.g. the delta model) and models based on cumulative reward (e.g. the decay model) can account for choice preferences. In a binary-outcome choice task, participants selected between pairs of options that had reward probabilities of 0.65 (A) versus 0.35 (B) or 0.75 (C) versus 0.25 (D). Crucially, during training there were twice the number of AB trials as CD trials, such that option A was associated with higher cumulative reward, while option C gave higher average reward. Participants then decided between novel combinations of options (e.g., AC). Most participants preferred option A over C, a result predicted by the Decay model, but not the Delta model. We also compared the Delta and Decay models to both more simplified as well as more complex models that assumed additional mechanisms, such as representation of uncertainty. Overall, models that assume learning about cumulative reward provided the best account of the data.", "AuthorKeywords": ["Decay rule", "Delta rule", "Prediction error", "Probability learning", "Reinforcement learning", "Reward frequency"], "IndexKeywords": ["Adult", "Choice Behavior", "Female", "Humans", "Male", "Models, Psychological", "Probability Learning", "Reinforcement, Psychology", "Reward", "Young Adult"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85070689787", "SubjectAreas": [["Experimental and Cognitive Psychology", "PSYC", "3205"], ["Language and Linguistics", "ARTS", "1203"], ["Developmental and Educational Psychology", "PSYC", "3204"], ["Linguistics and Language", "SOCI", "3310"], ["Cognitive Neuroscience", "NEUR", "2805"]], "AuthorData": {"56478680600": {"Name": "Don H.J.", "AuthorID": "56478680600", "AffiliationID": "60020547", "AffiliationName": "Texas A&M University"}, "57202777672": {"Name": "Cornwall A.C.", "AuthorID": "57202777672", "AffiliationID": "60020547", "AffiliationName": "Texas A&M University"}, "15128203000": {"Name": "Worthy D.A.", "AuthorID": "15128203000", "AffiliationID": "60020547", "AffiliationName": "Texas A&M University"}, "35322991600": {"Name": "Otto A.R.", "AuthorID": "35322991600", "AffiliationID": "60002494", "AffiliationName": "McGill University"}, "26631881900": {"Name": "Davis T.", "AuthorID": "26631881900", "AffiliationID": "60021285", "AffiliationName": "Texas Tech University"}}}