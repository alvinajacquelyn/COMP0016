{"Title": "Avoiding degradation in deep feed-forward networks by phasing out skip-connections", "Year": 2018, "Source": "Lect. Notes Comput. Sci.", "Volume": "11141 LNCS", "Issue": null, "Art.No": null, "PageStart": 447, "PageEnd": 456, "CitedBy": 3, "DOI": "10.1007/978-3-030-01424-7_44", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85054830527&origin=inward", "Abstract": "\u00a9 Springer Nature Switzerland AG 2018.A widely observed phenomenon in deep learning is the degradation problem: increasing the depth of a network leads to a decrease in performance on both test and training data. Novel architectures such as ResNets and Highway networks have addressed this issue by introducing various flavors of skip-connections or gating mechanisms. However, the degradation problem persists in the context of plain feed-forward networks. In this work we propose a simple method to address this issue. The proposed method poses the learning of weights in deep networks as a constrained optimization problem where the presence of skip-connections is penalized by Lagrange multipliers. This allows for skip-connections to be introduced during the early stages of training and subsequently phased out in a principled manner. We demonstrate the benefits of such an approach with experiments on MNIST, fashion-MNIST, CIFAR-10 and CIFAR-100 where the proposed method is shown to greatly decrease the degradation effect and is often competitive with ResNets.", "AuthorKeywords": ["Degradation", "Shattered/vanishing gradients", "Skip-connections"], "IndexKeywords": ["Constrained optimi-zation problems", "Degradation effect", "Feed-forward network", "Gating mechanisms", "Highway networks", "Novel architecture", "Shattered/vanishing gradients", "Training data"], "DocumentType": "Book Series", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85054830527", "SubjectAreas": [["Theoretical Computer Science", "MATH", "2614"], ["Computer Science (all)", "COMP", "1700"]], "AuthorData": {"56346664600": {"Name": "Monti R.P.", "AuthorID": "56346664600", "AffiliationID": "60084280, 60022148", "AffiliationName": "Gatsby Computational Neuroscience Unit, UCL"}, "36551620000": {"Name": "Tootoonian S.", "AuthorID": "36551620000", "AffiliationID": "60084280, 60022148", "AffiliationName": "Gatsby Computational Neuroscience Unit, UCL"}, "57212758374": {"Name": "Cao R.", "AuthorID": "57212758374", "AffiliationID": "60084280, 60022148", "AffiliationName": "Gatsby Computational Neuroscience Unit, UCL"}}}