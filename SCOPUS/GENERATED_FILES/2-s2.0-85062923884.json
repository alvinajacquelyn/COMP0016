{"Title": "Rate-accuracy trade-off in video classification with deep convolutional neural networks", "Year": 2018, "Source": "Proc. Int. Conf. Image Process. ICIP", "Volume": null, "Issue": null, "Art.No": null, "PageStart": 793, "PageEnd": 797, "CitedBy": 1, "DOI": "10.1109/ICIP.2018.8451666", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062923884&origin=inward", "Abstract": "\u00a9 2018 IEEE.Advanced video classification systems decode video frames to derive the necessary texture and motion representations for ingestion and analysis by spatio-temporal deep convolutional neural networks (CNNs). However, when considering visual Internet -of- Things applications, surveillance systems and semantic crawlers of large video repositories, the compressed video content and the CNN-based semantic analysis parts do not tend to be co-located. This necessitates the transport of compressed video over networks and incurs significant overhead in bandwidth and energy consumption, thereby significantly undermining the deployment potential of such systems. In this paper, we investigate the trade-off between the encoding bitrate and the achievable accuracy of CNN-based video classification that ingests AVC/H.264 encoded videos. Instead of entire compressed video bitstreams, we only retain motion vector and selected texture information at significantly reduced bitrates. Based on two CNN architectures and two action recognition datasets, we achieve 38%-59% saving in bitrate with marginal impact in classification accuracy. A simple rate-based selection between the two CNNs shows that even further bitrate savings are possible with graceful degradation in accuracy. This may allow for rate/accuracy-optimized CNN-based video classification over networks.", "AuthorKeywords": ["Convolutional neural networks", "Video classification", "Video streaming"], "IndexKeywords": ["Action recognition", "Classification accuracy", "Convolutional neural network", "Graceful degradation", "Motion representation", "Surveillance systems", "Texture information", "Video classification"], "DocumentType": "Conference Proceeding", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85062923884", "SubjectAreas": [["Software", "COMP", "1712"], ["Computer Vision and Pattern Recognition", "COMP", "1707"], ["Signal Processing", "COMP", "1711"]], "AuthorData": {"56939943000": {"Name": "Abbas A.", "AuthorID": "56939943000", "AffiliationID": "60022148", "AffiliationName": "Dept. of Electronic Electrical Engineering, University College London"}, "56988993100": {"Name": "Chadha A.", "AuthorID": "56988993100", "AffiliationID": "60022148", "AffiliationName": "Dept. of Electronic Electrical Engineering, University College London"}, "57207530477": {"Name": "Andreopoulos Y.", "AuthorID": "57207530477", "AffiliationID": "60022148", "AffiliationName": "Dept. of Electronic Electrical Engineering, University College London"}, "13005552000": {"Name": "Jubran M.", "AuthorID": "13005552000", "AffiliationID": "60072735", "AffiliationName": "Dept. of Electrical Computer Engineering, Birzeit University"}}}