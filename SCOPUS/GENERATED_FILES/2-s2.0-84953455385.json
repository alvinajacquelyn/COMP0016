{"Title": "Deep Filter Banks for Texture Recognition, Description, and Segmentation", "Year": 2016, "Source": "Int J Comput Vision", "Volume": "118", "Issue": 1, "Art.No": null, "PageStart": 65, "PageEnd": 94, "CitedBy": 175, "DOI": "10.1007/s11263-015-0872-3", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84953455385&origin=inward", "Abstract": "\u00a9 2015, The Author(s).Visual textures have played a key role in image understanding because they convey important semantics of images, and because texture representations that pool local image descriptors in an orderless manner have had a tremendous impact in diverse applications. In this paper we make several contributions to texture understanding. First, instead of focusing on texture instance and material category recognition, we propose a human-interpretable vocabulary of texture attributes to describe common texture patterns, complemented by a new describable texture dataset for benchmarking. Second, we look at the problem of recognizing materials and texture attributes in realistic imaging conditions, including when textures appear in clutter, developing corresponding benchmarks on top of the recently proposed OpenSurfaces dataset. Third, we revisit classic texture represenations, including bag-of-visual-words and the Fisher vectors, in the context of deep learning and show that these have excellent efficiency and generalization properties if the convolutional layers of a deep model are used as filter banks. We obtain in this manner state-of-the-art performance in numerous datasets well beyond textures, an efficient method to apply deep features to image regions, as well as benefit in transferring features from one domain to another.", "AuthorKeywords": ["Convolutional neural networks", "Datasets and benchmarks", "Filter banks", "Fisher vectors", "Texture and material recognition", "Visual attributes"], "IndexKeywords": ["Convolutional neural network", "Fisher vectors", "Generalization properties", "Local image descriptors", "Material recognition", "State-of-the-art performance", "Texture representation", "Visual attributes"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 1, "EID": "2-s2.0-84953455385", "SubjectAreas": [["Software", "COMP", "1712"], ["Computer Vision and Pattern Recognition", "COMP", "1707"], ["Artificial Intelligence", "COMP", "1702"]], "AuthorData": {"24829301400": {"Name": "Cimpoi M.", "AuthorID": "24829301400", "AffiliationID": "60026851", "AffiliationName": "University of Oxford"}, "14036614600": {"Name": "Vedaldi A.", "AuthorID": "14036614600", "AffiliationID": "60026851", "AffiliationName": "University of Oxford"}, "23389726300": {"Name": "Maji S.", "AuthorID": "23389726300", "AffiliationID": "60014313", "AffiliationName": "University of Massachusetts Amherst"}, "9250105400": {"Name": "Kokkinos I.", "AuthorID": "9250105400", "AffiliationID": "60105988, 60106088", "AffiliationName": "CentraleSup\u00e9lec/INRIA-Saclay"}}}