{"Title": "Can deep learning revolutionize mobile sensing?", "Year": 2015, "Source": "HotMobile - Int. Workshop Mob. Comput. Syst. Appl.", "Volume": null, "Issue": null, "Art.No": null, "PageStart": 117, "PageEnd": 122, "CitedBy": 130, "DOI": "10.1145/2699343.2699349", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84942430054&origin=inward", "Abstract": "Copyright \u00a9 2015 ACM.Sensor-equipped smartphones and wearables are transform- ing a variety of mobile apps ranging from health monitoring to digital assistants. However, reliably inferring user behav- ior and context from noisy and complex sensor data collected under mobile device constraints remains an open problem, and a key bottleneck to sensor app development. In recent years, advances in the field of deep learning have resulted in nearly unprecedented gains in related inference tasks such as speech and object recognition. However, although mobile sensing shares many of the same data modeling challenges, we have yet to see deep learning be systematically studied within the sensing domain. If deep learning could lead to significantly more robust and efficient mobile sensor infer- ence it would revolutionize the field by rapidly expanding the number of sensor apps ready for mainstream usage. In this paper, we provide preliminary answers to this po- tentially game-changing question by prototyping a low-power Deep Neural Network (DNN) inference engine that exploits both the CPU and DSP of a mobile device SoC. We use this engine to study typical mobile sensing tasks (e.g., activity recognition) using DNNs, and compare results to learning techniques in more common usage. Our early findings pro- vide illustrative examples of DNN usage that do not over- burden modern mobile hardware, while also indicating how they can improve inference accuracy. Moreover, we show DNNs can gracefully scale to larger numbers of inference classes and can be exibly partitioned across mobile and remote resources. Collectively, these results highlight the critical need for further exploration as to how the field of mobile sensing can best make use of advances in deep learn- ing towards robust and efficient sensor inference.", "AuthorKeywords": ["Activity Recognition", "Deep Learning", "Deep Neural Network", "Mobile Sensing"], "IndexKeywords": ["Activity recognition", "Deep learning", "Deep neural networks", "Digital assistants", "Health monitoring", "Learning techniques", "Mobile sensing", "Remote resources"], "DocumentType": "Conference Proceeding", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-84942430054", "SubjectAreas": [["Computer Networks and Communications", "COMP", "1705"], ["Computer Science Applications", "COMP", "1706"]], "AuthorData": {"23135333200": {"Name": "Lane N.", "AuthorID": "23135333200", "AffiliationID": "60021726", "AffiliationName": "Microsoft Research"}, "56411711300": {"Name": "Georgiev P.", "AuthorID": "56411711300", "AffiliationID": "60031101", "AffiliationName": "University of Cambridge"}}}