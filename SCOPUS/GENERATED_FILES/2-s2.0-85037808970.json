{"Title": "Probabilistic reasoning with abstract argumentation frameworks", "Year": 2017, "Source": "J Artif Intell Res", "Volume": "59", "Issue": null, "Art.No": null, "PageStart": 565, "PageEnd": 611, "CitedBy": 34, "DOI": "10.1613/jair.5393", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85037808970&origin=inward", "Abstract": "\u00a9 2017 AI Access Foundation. All rights reserved.Argumentation offers an appealing way of representing and evaluating arguments and counterarguments. This approach can be enhanced by considering probability assignments on arguments, allowing for a quantitative treatment of formal argumentation. In this paper, we regard the assignment as denoting the degree of belief that an agent has in an argument being acceptable. While there are various interpretations of this, an example is how it could be applied to a deductive argument. Here, the degree of belief that an agent has in an argument being acceptable is a combination of the degree to which it believes the premises, the claim, and the derivation of the claim from the premises. We consider constraints on these probability assignments, inspired by crisp notions from classical abstract argumentation frameworks and discuss the issue of probabilistic reasoning with abstract argumentation frameworks. Moreover, we consider the scenario when assessments on the probabilities of a subset of the arguments are given and the probabilities of the remaining arguments have to be derived, taking both the topology of the argumentation framework and principles of probabilistic reasoning into account. We generalise this scenario by also considering inconsistent assessments, i.e., assessments that contradict the topology of the argumentation framework. Building on approaches to inconsistency measurement, we present a general framework to measure the amount of conflict of these assessments and provide a method for inconsistency-tolerant reasoning.", "AuthorKeywords": null, "IndexKeywords": ["Abstract argumentation", "Argumentation frameworks", "Degree of belief", "Formal argumentation", "Inconsistency-tolerant reasonings", "Probabilistic reasoning", "Probability assignment", "Quantitative treatment"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 1, "EID": "2-s2.0-85037808970", "SubjectAreas": [["Artificial Intelligence", "COMP", "1702"]], "AuthorData": {"7402779550": {"Name": "Hunter A.", "AuthorID": "7402779550", "AffiliationID": "60022148", "AffiliationName": "University College London"}, "25825630400": {"Name": "Thimm M.", "AuthorID": "25825630400", "AffiliationID": "60006429", "AffiliationName": "University of Koblenz-Landau"}}}