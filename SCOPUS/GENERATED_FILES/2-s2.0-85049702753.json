{"Title": "Principles for Designing Body-Centered Auditory Feedback", "Year": 2017, "Source": "The Wiley Handb. of Hum. Comput. Interact. Set", "Volume": "1", "Issue": null, "Art.No": null, "PageStart": 371, "PageEnd": 403, "CitedBy": 7, "DOI": "10.1002/9781118976005.ch18", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85049702753&origin=inward", "Abstract": "\u00a9 2018 John Wiley & Sons Ltd.Our body can be seen as an anchor that tightly connects us with the surrounding physical world. Concepts of body-centred interaction have been successfully applied in virtual and augmented reality, however, mainly in the visual domain. Still, we interact with the environment through our body, and these interactions mostly always produce sounds. These sounds have information about involved movements, external objects, agents and also about our own body. In addition, sounds of our breathing or heartbeat constitute an important part of our body representation that can be called \"sonic self-avatar\". Current interactive multimodal technologies allow altering and feeding back body-centred sounds to the user in real-time. Such changes in auditory feedback often have a profound impact on self-body perception, triggering perceptual, cognitive and emotional changes. In this chapter we show how recent neuroscientifically and psychologically grounded insights can guide the design of new, enhanced interactive technologies for physical and virtual environments, objects and agents; forms of interaction and body expressivity; and for augmenting self-perceptions and facilitating movement and motor learning. We also discuss how new HCI applications grounded in these principles may be used to overcome psychological and physical barriers in people with specific health conditions. We end the chapter by listing open research challenges and suggesting some possible future research and innovation directions that would benefit from a body-centred sound design.", "AuthorKeywords": ["Body capabilities", "Body-centered auditory feedback", "Emotional state", "Interactive technologies", "Mixed reality environments", "Movement dynamics", "Physical rehabilitation"], "IndexKeywords": null, "DocumentType": "Book", "PublicationStage": null, "OpenAccess": 0, "EID": "2-s2.0-85049702753", "SubjectAreas": [["Psychology (all)", "PSYC", "3200"]], "AuthorData": {"23569030500": {"Name": "Tajadura-Jim\u00e9nez A.", "AuthorID": "23569030500", "AffiliationID": "60022148", "AffiliationName": "Interaction Centre, University College London (UCL)"}, "6602671345": {"Name": "Bianchi-Berthouze N.", "AuthorID": "6602671345", "AffiliationID": "60022148", "AffiliationName": "Interaction Centre, University College London (UCL)"}, "15133296000": {"Name": "V\u00e4ljam\u00e4e A.", "AuthorID": "15133296000", "AffiliationID": "60068864", "AffiliationName": "School of Digital Technologies, Tallinn University"}, "57204340555": {"Name": "Bevilacqua F.", "AuthorID": "57204340555", "AffiliationID": "60013528", "AffiliationName": "Sound Music Movement Interaction Team, Institute for Research and Coordination in Acoustics/Music (IRCAM)"}}}