{"Title": "Inefficiencies in the cache hierarchy: A sensitivity study of cacheline size with mobile workloads", "Year": 2015, "Source": "ACM Int. Conf. Proc. Ser.", "Volume": "05-08-October-2015", "Issue": null, "Art.No": null, "PageStart": 235, "PageEnd": 245, "CitedBy": 0, "DOI": "10.1145/2818950.2818980", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84959432468&origin=inward", "Abstract": "\u00a9 2015 Copyright held by the owner/author(s).With the rising number of cores in mobile devices, the cache hierarchy in mobile application processors gets deeper, and the cache size gets bigger. However, the cacheline size remained relatively constant over the last decade in mobile application processors. In this work, we investigate whether the cacheline size in mobile application processors is due for a refresh, by looking at inefciencies in the cache hierarchy which tend to be exacerbated when increasing the cacheline size: false sharing and cacheline utilization. Firstly, we look at false sharing, which is more likely to arise at larger cacheline sizes and can severely impact performance. False sharing occurs when non-shared data structures, mapped onto the same cacheline, are being accessed by threads running on different cores, causing avoidable invalidations and subsequent misses. False sharing has been found in various places such as scientific workloads and real applications. We find that whilst increasing the cacheline size does increase false sharing, it still is negligible when compared to known cases of false sharing in scientific workloads, due to the limited level of thread-level parallelism in mobile workloads. Secondly, we look at cacheline utilization which measures the number of bytes in a cacheline actually used by the processor. This effect has been investigated under various names for a multitude of server and desktop applications. As a low cacheline utilization implies that very little of the fetched cachelines was used by the processor, this causes waste in bandwidth and energy in moving data across the memory hierarchy. The energy cost associated with data movements is much higher compared to logic operations, increasing the need for cache effciency, especially in the case of an energy-constrained platform like a mobile device. We find that the cacheline utilization of mobile workloads is low in general, decreasing when increasing the cacheline size When increasing the cacheline size from 64 bytes to 128 bytes, the number of misses will be reduced by 10%-30%, depending on the workload. However, because of the low cacheline utilization, this more than doubles the amount of unused trafic to the L1 caches. Using the cacheline utilization as a metric in this way, illustrates an important point. If a change in cacheline size would only be assessed on its local effects, we find that this change in cacheline size will only have advantages as the miss rate decreases. However, at system level, this change will increase the stress on the bus and increase the amount of wasted energy due to unused trafic. Using cacheline utilization as a metric underscores the need for system-level research when changing characteristics of the cache hierarchy.", "AuthorKeywords": ["Cacheline utilization", "False sharing", "Mobile devices", "Mobile workloads"], "IndexKeywords": ["Desktop applications", "False sharing", "Mobile application processor", "Mobile workloads", "Scientific workloads", "Sensitivity studies", "Shared data structure", "Thread level parallelism"], "DocumentType": "Conference Proceeding", "PublicationStage": null, "OpenAccess": 0, "EID": "2-s2.0-84959432468", "SubjectAreas": [["Software", "COMP", "1712"], ["Human-Computer Interaction", "COMP", "1709"], ["Computer Vision and Pattern Recognition", "COMP", "1707"], ["Computer Networks and Communications", "COMP", "1705"]], "AuthorData": {"55321228000": {"Name": "Van Laer A.", "AuthorID": "55321228000", "AffiliationID": "60022148", "AffiliationName": "University College London"}, "56028995000": {"Name": "Wang W.", "AuthorID": "56028995000", "AffiliationID": "60099299", "AffiliationName": "ARM Research Cambridge"}, "8645223700": {"Name": "Emmons C.", "AuthorID": "8645223700", "AffiliationID": "112645548", "AffiliationName": "ARM Research Austin"}}}