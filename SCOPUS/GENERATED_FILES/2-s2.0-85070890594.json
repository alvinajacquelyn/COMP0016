{"Title": "NeuroMask: Explaining predictions of deep neural networks through mask learning", "Year": 2019, "Source": "Proc. - IEEE Int. Conf. Smart Comput., SMARTCOMP", "Volume": null, "Issue": null, "Art.No": null, "PageStart": 81, "PageEnd": 86, "CitedBy": 1, "DOI": "10.1109/SMARTCOMP.2019.00033", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85070890594&origin=inward", "Abstract": "\u00a9 2019 IEEE.Deep Neural Networks (DNNs) deliver state-of-the-art performance in many image recognition and understanding applications. However, despite their outstanding performance, these models are black-boxes and it is hard to understand how they make their decisions. Over the past few years, researchers have studied the problem of providing explanations of why DNNs predicted their results. However, existing techniques are either obtrusive, requiring changes in model training, or suffer from low output quality. In this paper, we present a novel method, NeuroMask, for generating an interpretable explanation of classification model results. When applied to image classification models, NeuroMask identifies the image parts that are most important to classifier results by applying a mask that hides/reveals different parts of the image, before feeding it back into the model. The mask values are tuned by minimizing a properly designed cost function that preserves the classification result and encourages producing an interpretable mask. Experiments using state-of-art Convolutional Neural Networks for image recognition on different datasets (CIFAR-10 and ImageNet) show that NeuroMask successfully localizes the parts of the input image which are most relevant to the DNN decision. By showing a visual quality comparison between NeuroMask explanations and those of other methods, we find NeuroMask to be both accurate and interpretable.", "AuthorKeywords": ["Deep learning", "Image recognition", "Interpretability", "Neural networks"], "IndexKeywords": ["Classification models", "Classification results", "Convolutional neural network", "Interpretability", "Model training", "Output quality", "State-of-the-art performance", "Visual qualities"], "DocumentType": "Conference Proceeding", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85070890594", "SubjectAreas": [["Artificial Intelligence", "COMP", "1702"], ["Computer Networks and Communications", "COMP", "1705"], ["Computer Science Applications", "COMP", "1706"], ["Hardware and Architecture", "COMP", "1708"], ["Safety, Risk, Reliability and Quality", "ENGI", "2213"]], "AuthorData": {"55322834800": {"Name": "Alzantot M.", "AuthorID": "55322834800", "AffiliationID": "60027550", "AffiliationName": "Computer Science Dept., UCLA"}, "57204013873": {"Name": "Widdicombe A.", "AuthorID": "57204013873", "AffiliationID": "60022148", "AffiliationName": "Computer Science Dept., UCL"}, "7003972937": {"Name": "Julier S.", "AuthorID": "7003972937", "AffiliationID": "60022148", "AffiliationName": "Computer Science Dept., UCL"}, "35599699800": {"Name": "Srivastava M.", "AuthorID": "35599699800", "AffiliationID": "60022148", "AffiliationName": "Computer Science Dept., UCL"}}}