{"Title": "Indoor pedestrian dead reckoning calibration by visual tracking and map information", "Year": 2018, "Source": "Proc. IEEE Conf. Ubiquitous Position., Indoor Navig. Location-Based Serv., UPINLBS", "Volume": null, "Issue": null, "Art.No": null, "PageStart": null, "PageEnd": null, "CitedBy": 1, "DOI": "10.1109/UPINLBS.2018.8559925", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85060214356&origin=inward", "Abstract": "\u00a9 2018 IEEE.Currently, Pedestrian Dead Reckoning (PDR) systems are becoming an important tool in indoor navigation. This is mainly due to the development of affordable and portable Micro Electro-Mechanical Systems (MEMS) on smartphones and decreased requirement of additional infrastructures in indoor areas. The main drawback to this technology remains the problem of drift accumulation and the need for support from external positioning systems. Vision-aided inertial navigation is one possible solution to that problem. This solution has become more popular in indoor localization with improved satisfaction compared to individual PDR system. Previous studies have used fixed platforms and visual tracking employed feature-extraction-based methods. This paper proposes a distributed implementation of positioning system and uses deep learning for visual tracking. Meanwhile, as both inertial navigation and optical systems can provide only relative positioning information, this paper proposes a method to integrate digital maps with real geographical coordinates to supply absolute location. This hybrid system has been tested on two common operation systems of smartphones using iOS and Android systems, based on corresponding data collection apps respectively, in order to test the robustness of method. It also uses two different methods for calibration, by time synchronization of positions and heading calibration based on time steps. Results demonstrate that localization information collected from both operating systems can be significantly improved after integrating with visual tracking data.", "AuthorKeywords": ["indoor navigation", "pedestrian dead reckoning", "sensor fusion", "smartphone positioning", "visual tracking"], "IndexKeywords": ["Distributed implementation", "In-door navigations", "Micro electromechanical system (MEMS)", "Pedestrian dead reckoning systems", "Pedestrian dead reckonings", "Sensor fusion", "Vision-aided inertial navigation", "Visual Tracking"], "DocumentType": "Conference Proceeding", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85060214356", "SubjectAreas": [["Computational Mathematics", "MATH", "2605"], ["Control and Optimization", "MATH", "2606"], ["Instrumentation", "PHYS", "3105"]], "AuthorData": {"57203152001": {"Name": "Yan J.", "AuthorID": "57203152001", "AffiliationID": "60104720", "AffiliationName": "International Doctoral Innovation Centre, University of Nottingham"}, "57203156837": {"Name": "He G.", "AuthorID": "57203156837", "AffiliationID": "60104720", "AffiliationName": "Department of Geographical Science, University of Nottingham"}, "55626206500": {"Name": "Basiri A.", "AuthorID": "55626206500", "AffiliationID": "60022148", "AffiliationName": "Centre for Advanced Spatial Analysis, University College London"}, "36898196900": {"Name": "Hancock C.", "AuthorID": "36898196900", "AffiliationID": "60104720", "AffiliationName": "Department of Civil Engineering, University of Nottingham"}}}